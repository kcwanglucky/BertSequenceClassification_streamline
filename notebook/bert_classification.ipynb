{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "bert_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1xaKCLqWMWaK",
        "33Fz89TjAHtv",
        "urkhZ-u4gToK"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcwanglucky/bert_run_lm_streamline/blob/master/bert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eNvXhd_oNzU",
        "colab_type": "text"
      },
      "source": [
        "### File to put in current directory:\n",
        "intent.csv: 原本labeled data\\\n",
        "cleaned_wo_punc.csv: 將原本的4個unlabeled data檔案合併（共17000筆），並把多餘的標點符號\b空格刪除了\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xaKCLqWMWaK",
        "colab_type": "text"
      },
      "source": [
        "### Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c64R13hNL2P1",
        "colab_type": "code",
        "outputId": "910ae410-528d-4b3f-813c-d7358ab0ea88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'ai-report-240709'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDhPGA_iMdWk",
        "colab_type": "code",
        "outputId": "d3084ce4-55de-4d94-b351-63538e1c6b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Download the file from a given Google Cloud Storage bucket.\n",
        "!gsutil cp gs://luckykcw/cleaned_w_embed.tsv ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://luckykcw/cleaned_w_embed.tsv...\n",
            "\\ [1 files][ 33.4 MiB/ 33.4 MiB]                                                \n",
            "Operation completed over 1 objects/33.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2pMM4Oc_u7T",
        "colab_type": "code",
        "outputId": "4a3e7a6d-aef2-4a6f-ee58-1a2ee5ec4903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Copy raw intent.csv file to environment\n",
        "!gsutil cp gs://luckykcw/intent.csv ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://luckykcw/intent.csv...\n",
            "/ [0 files][    0.0 B/277.0 KiB]                                                \r-\r- [1 files][277.0 KiB/277.0 KiB]                                                \r\n",
            "Operation completed over 1 objects/277.0 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqP0NcDRNVrG",
        "colab_type": "code",
        "outputId": "242173b6-d7df-4ef8-bea9-574e4344fd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLKze1xML-Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My Drive/ESUN/0303_intent_newclass ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p_KK91TlqrO",
        "colab_type": "text"
      },
      "source": [
        "### 下載並安裝 transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4zdhAV8Unid",
        "colab_type": "code",
        "outputId": "9869a825-94fe-4932-c445-89b077654dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!cp -r drive/My\\ Drive/ESUN/0206_data_lm_ft/transformers .\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 5.9MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 35.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 39.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 43.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 28.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 31.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 21.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 19.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 20.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 20.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 52.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=f690fb79508691b13b59d2c6b667502aa6b783994d165ccd75cc084f29395c31\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tb9PhUOMdmT",
        "colab_type": "text"
      },
      "source": [
        "### Import package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jayXM4VWofZs",
        "colab_type": "code",
        "outputId": "e9689a05-62c0-43b2-f826-b803a1108c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svst1jYBo9u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.read_csv(\"intent.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz3r3VyHpCZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 只留取index及question coluumn\n",
        "df_data = df_data.iloc[:, [0, 2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xTbP2LLZ7qg",
        "colab_type": "text"
      },
      "source": [
        "### **1. Train a bert with current labeled data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33Fz89TjAHtv",
        "colab_type": "text"
      },
      "source": [
        "#### Data Preprocessing (此function用來過濾掉太長的question或是sample太少的種類)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6_kfz32NHab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 把各組數量大於mineachgroup的及Question長度小於maxlength的取出來\n",
        "# 然後再轉換index，讓被刪除的index不要留空\n",
        "# Output一個更新後的dataframe\n",
        "def preprocessing(df_data, mineachgroup, maxlength):\n",
        "    # filter out long question\n",
        "    df_data = df_data[~(df_data.question.apply(lambda x : len(x)) > maxlength)]\n",
        "\n",
        "    freq = df_data['index'].value_counts()\n",
        "    idxs = np.array(freq.index)\n",
        "    counts = freq\n",
        "\n",
        "    # index numbers of groups with count >= mineachgroup\n",
        "    list_idx = [i for i, c in zip(idxs, counts) if c > mineachgroup]\n",
        "\n",
        "    # filter out data with \"index\" in list_idx \n",
        "    df_data = df_data[df_data['index'].isin(list_idx)]\n",
        "\n",
        "    # # Redindex the topic group so that it is continuous\n",
        "    # index = df_data[\"index\"]\n",
        "    # index2label = {idx:val for idx, val in enumerate(index.unique()) }\n",
        "    # label2index = {val:idx for idx, val in index2label.items() }\n",
        "    # def getindex4label(label):\n",
        "    #     return label2index[label]\n",
        "    \n",
        "    # df_data[\"index\"] = df_data[\"index\"].apply(getindex4label) \n",
        "\n",
        "    return df_data    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKOLbbCUQ_hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data_prep = preprocessing(df_data, 4, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DcE4XYjTwmq",
        "colab_type": "text"
      },
      "source": [
        "#### Redindex the topic group so that it is continuous"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQxbuGuHC5hD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reIndex(df):\n",
        "    index = df[\"index\"]\n",
        "    index2label = {idx:val for idx, val in enumerate(index.unique()) }\n",
        "    label2index = {val:idx for idx, val in index2label.items() }\n",
        "    def getindex4label(label):\n",
        "        return label2index[label]\n",
        "    df[\"index\"] = df[\"index\"].apply(getindex4label) \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKL1dK9rDi2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = reIndex(df_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8Kck5ANabN9",
        "colab_type": "text"
      },
      "source": [
        "#### Create split based on percentage (Get every index sampled) \n",
        "邏輯：每種class都取perct %的資料進去training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDLsXe0_LnbI",
        "colab_type": "code",
        "outputId": "7618e44a-49fd-4c86-b39d-2948081c5f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NUM_LABELS = len(df_data['index'].value_counts())\n",
        "print(\"label的數量：{}\".format(NUM_LABELS))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label的數量：499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DteEGV_Makru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 從各類別random sample出fraction比例的資料集\n",
        "    data: df data that includes the \"index\" and \"question\" column\n",
        "    fraction: the fraction of data you want to sample (ex: 0.7)\n",
        "\"\"\" \n",
        "def bootstrap(data, fraction):\n",
        "    # This function will be applied on each group of instances of the same\n",
        "    # class in data.\n",
        "    def sampleClass(classgroup):\n",
        "        return classgroup.sample(frac = fraction)\n",
        "\n",
        "    samples = data.groupby('index').apply(sampleClass)\n",
        "    \n",
        "    # If you want an index which is equal to the row in `data` where the sample came from\n",
        "    # If you don't change it then you'll have a multiindex with level 0\n",
        "    # being the class and level 1 being the row in `data` where\n",
        "    # the sample came from.\n",
        "    samples.index = samples.index.get_level_values(1)\n",
        "    return samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwFNv8xoLnbx",
        "colab_type": "text"
      },
      "source": [
        "#### 輸出預處理解果(train and test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_1qB8l1U4wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 將原本全部的cleaned data依照指定的比例分成train/val/test set，\n",
        "    並output成tsv檔到環境中(檔名ex: 70%train.tsv)\n",
        "    df: df data that includes the \"index\" and \"question\" column\n",
        "    fraction: fraction of all data to be assigned to training set\n",
        "    The remaining (1-fraction) data will be equally splitted between\n",
        "    validation and testing set\n",
        "\"\"\"\n",
        "\n",
        "def output_split(df, fraction = 0.7):\n",
        "    df_train = bootstrap(df, fraction)\n",
        "    df_remain = pd.concat([df_train, df]).drop_duplicates(keep=False)\n",
        "    df_val = df_remain.sample(frac = 0.5)\n",
        "    df_test = pd.concat([df_val, df_remain]).drop_duplicates(keep=False)\n",
        "\n",
        "    # 放入label資料夾，以區分出之後unlabel的資料\n",
        "    path = os.path.join(\"data\", \"0226label\")\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    print(\"訓練樣本數：\", len(df_train))\n",
        "    df_train.to_csv(os.path.join(path, str(int(fraction * 100))+\"%train.tsv\"), sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"validation樣本數：\", len(df_val))\n",
        "    df_val.to_csv(os.path.join(path, str(int(fraction * 100))+\"%val.tsv\"), sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"預測樣本數：\", len(df_test))\n",
        "    df_test.to_csv(os.path.join(path, str(int(fraction * 100))+\"%test.tsv\"), sep=\"\\t\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9HYzz56cqOs",
        "colab_type": "code",
        "outputId": "8ad80fc5-85fd-4176-eeed-63406d37a5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "output_split(df_data, 0.7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練樣本數： 3177\n",
            "validation樣本數： 625\n",
            "預測樣本數： 625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yztlVFjlel8F",
        "colab_type": "text"
      },
      "source": [
        "#### 讀取前面預處理結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv9EcAIzepdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = os.path.join(\"data\", \"0226label\")\n",
        "fraction = 0.7\n",
        "train_path = os.path.join(path, str(int(fraction * 100))+\"%train.tsv\")\n",
        "val_path = os.path.join(path, str(int(fraction * 100))+\"%val.tsv\")\n",
        "test_path = os.path.join(path, str(int(fraction * 100))+\"%test.tsv\")\n",
        "df_train = pd.read_csv(train_path, sep=\"\\t\").fillna(\"\")\n",
        "df_val = pd.read_csv(val_path, sep=\"\\t\").fillna(\"\")\n",
        "df_test = pd.read_csv(test_path, sep=\"\\t\").fillna(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKTUAxHtftUM",
        "colab_type": "text"
      },
      "source": [
        "#### 用OnlineQueryDataset來存取資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DltDuxGLncG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    實作一個可以用來讀取訓練 / 測試集的 Dataset，此 Dataset 每次將 tsv 裡的一筆成對句子\n",
        "    轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
        "    - tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
        "    - segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
        "    - label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
        "\"\"\"\n",
        "from torch.utils.data import Dataset\n",
        "   \n",
        "class OnlineQueryDataset(Dataset):\n",
        "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
        "    # mode: in [\"train\", \"test\", \"val\"]\n",
        "    # tokenizer: one of bert tokenizer\n",
        "    # perc: percentage of data to put in training set\n",
        "    # path: if given, then read data from the path(ex training set)\n",
        "    def __init__(self, mode, tokenizer, perc = 70, path = None):\n",
        "        assert mode in [\"train\", \"val\", \"test\"]  # 一般訓練你會需要 dev set\n",
        "        self.mode = mode\n",
        "        if not path: \n",
        "            path = os.path.join(\"data\", str(perc) + \"%\" + mode + \".tsv\")\n",
        "        self.df = pd.read_csv(path, sep=\"\\t\").fillna(\"\")\n",
        "        self.len = len(self.df)\n",
        "        self.tokenizer = tokenizer \n",
        "    \n",
        "    # 定義回傳一筆訓練 / 測試數據的函式\n",
        "    #@pysnooper.snoop()  # 加入以了解所有轉換過程\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            text = self.df.iloc[idx, 1]\n",
        "            label_tensor = None\n",
        "        elif self.mode == \"val\":\n",
        "            label, text = self.df.iloc[idx, :].values\n",
        "            label_tensor = torch.tensor(label)\n",
        "        else:\n",
        "            label, text = self.df.iloc[idx, :].values\n",
        "            # 將label文字也轉換成索引方便轉換成 tensor\n",
        "            label_tensor = torch.tensor(label)\n",
        "            \n",
        "        \"\"\"\n",
        "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens_a = self.tokenizer.tokenize(text_a)\n",
        "        word_pieces += tokens_a + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # 第二個句子的 BERT tokens\n",
        "        tokens_b = self.tokenizer.tokenize(text_b)\n",
        "        word_pieces += tokens_b + [\"[SEP]\"]\n",
        "        len_b = len(word_pieces) - len_a\n",
        "        \"\"\"\n",
        "        # 建立句子的 BERT tokens \n",
        "        word_pieces = [\"[CLS]\"]\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        word_pieces += tokens + [\"[SEP]\"]\n",
        "        len_a = len(word_pieces)\n",
        "        \n",
        "        # 將整個 token 序列轉換成索引序列\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "        tokens_tensor = torch.tensor(ids)\n",
        "        \n",
        "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
        "        segments_tensor = torch.tensor([1] * len_a, dtype=torch.long)\n",
        "        \n",
        "        return (tokens_tensor, segments_tensor, label_tensor)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7v6LMgQrdzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXcHJ8trLncM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
        "trainset = OnlineQueryDataset(\"train\", tokenizer=tokenizer, path = \"data/0226label/70%train.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmfvmv3tg-cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valset = OnlineQueryDataset(\"val\", tokenizer=tokenizer, perc=70, path = \"data/0226label/70%val.tsv\")\n",
        "testset = OnlineQueryDataset(\"test\", tokenizer=tokenizer, perc=70, path = \"data/0226label/70%test.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqzqGSG-LncO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "實作可以一次回傳一個 mini-batch 的 DataLoader\n",
        "這個 DataLoader 吃我們上面定義的 `OnlineQueryDataset`，\n",
        "回傳訓練 BERT 時會需要的 4 個 tensors：\n",
        "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
        "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
        "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
        "- label_ids       : (batch_size)\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
        "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
        "# - tokens_tensor\n",
        "# - segments_tensor\n",
        "# - label_tensor\n",
        "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
        "def create_mini_batch(samples):\n",
        "    tokens_tensors = [s[0] for s in samples]\n",
        "    segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "    # 訓練集有 labels\n",
        "    if samples[0][2] is not None:\n",
        "        label_ids = torch.stack([s[2] for s in samples])\n",
        "    else:\n",
        "        label_ids = None\n",
        "    \n",
        "    # zero pad 到同一序列長度\n",
        "    tokens_tensors = pad_sequence(tokens_tensors, \n",
        "                                  batch_first=True)\n",
        "    segments_tensors = pad_sequence(segments_tensors, \n",
        "                                    batch_first=True)\n",
        "    \n",
        "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
        "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
        "    masks_tensors = torch.zeros(tokens_tensors.shape, \n",
        "                                dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(\n",
        "        tokens_tensors != 0, 1)\n",
        "    \n",
        "    return tokens_tensors, segments_tensors, masks_tensors, label_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOBwCgeoLncV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
        "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,  \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuXMsPSO_779",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valloader = DataLoader(valset, batch_size=BATCH_SIZE,  \n",
        "                         collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urkhZ-u4gToK",
        "colab_type": "text"
      },
      "source": [
        "#### Check first batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8_YBfzLncc",
        "colab_type": "code",
        "outputId": "6e916317-4092-4164-9bf5-bb262272abdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "data = next(iter(trainloader))\n",
        "\n",
        "tokens_tensors, segments_tensors, \\\n",
        "    masks_tensors, label_ids = data\n",
        "\n",
        "print(f\"\"\"\n",
        "tokens_tensors.shape   = {tokens_tensors.shape} \n",
        "{tokens_tensors}\n",
        "------------------------\n",
        "segments_tensors.shape = {segments_tensors.shape}\n",
        "{segments_tensors}\n",
        "------------------------\n",
        "masks_tensors.shape    = {masks_tensors.shape}\n",
        "{masks_tensors}\n",
        "------------------------\n",
        "label_ids.shape        = {label_ids.shape}\n",
        "{label_ids}\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens_tensors.shape   = torch.Size([64, 24]) \n",
            "tensor([[ 101,  100, 2791,  ...,    0,    0,    0],\n",
            "        [ 101, 4192, 7442,  ...,    0,    0,    0],\n",
            "        [ 101, 6296,  928,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101,  784, 7938,  ...,    0,    0,    0],\n",
            "        [ 101, 1912, 2395,  ...,    0,    0,    0],\n",
            "        [ 101, 9878, 1377,  ...,    0,    0,    0]])\n",
            "------------------------\n",
            "segments_tensors.shape = torch.Size([64, 24])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "------------------------\n",
            "masks_tensors.shape    = torch.Size([64, 24])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "------------------------\n",
            "label_ids.shape        = torch.Size([64])\n",
            "tensor([322, 458,  49, 213, 215,  70, 124, 403, 386, 432, 182,  22, 325, 418,\n",
            "        310, 289, 188, 355, 430, 420, 171, 245, 243, 292,  43,  12, 420, 224,\n",
            "        211, 245, 413,  61, 187, 175,  11, 236, 150, 435, 124, 310,  74, 198,\n",
            "        203, 220,  51, 273, 356, 497, 382, 273, 341, 166,  71,  60, 452, 493,\n",
            "        495,   6,  12, 350, 263, 399, 159, 198])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ZJZODiLnck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer.convert_ids_to_tokens(tokens_tensors[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B32p93SWLncp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_train[df_train[\"index\"] == 391]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtZdRNlgvl6",
        "colab_type": "text"
      },
      "source": [
        "#### Training step\n",
        "初始化一個BertForSequenceClassification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvEOjfwzLnct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "NUM_LABELS = len(df_data['index'].value_counts())\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0aCw0TnLnc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(model, dataloader, compute_acc=False):\n",
        "    predictions = None\n",
        "    correct = 0\n",
        "    total = 0\n",
        "      \n",
        "    with torch.no_grad():\n",
        "        # 遍巡整個資料集\n",
        "        for data in dataloader:\n",
        "            # 將所有 tensors 移到 GPU 上\n",
        "            if next(model.parameters()).is_cuda:\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
        "            \n",
        "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
        "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
        "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                            token_type_ids=segments_tensors, \n",
        "                            attention_mask=masks_tensors)\n",
        "            \n",
        "            logits = outputs[0]\n",
        "            _, pred = torch.max(logits.data, 1)\n",
        "            \n",
        "            # 用來計算訓練集的分類準確率\n",
        "            if compute_acc:\n",
        "                labels = data[3]\n",
        "                total += labels.size(0)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                \n",
        "            # 將當前 batch 記錄下來\n",
        "            if predictions is None:\n",
        "                predictions = pred\n",
        "            else:\n",
        "                predictions = torch.cat((predictions, pred))\n",
        "    \n",
        "    if compute_acc:\n",
        "        acc = correct / total\n",
        "        return predictions, acc\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIDSG8E-k8BH",
        "colab_type": "code",
        "outputId": "d99c83c7-3ffc-43d4-d4a9-8d1f5032eee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "pred, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "print(\"classification acc:\", acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "classification acc: 0.0015738117721120553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3VBOZ5CLnc5",
        "colab_type": "code",
        "outputId": "543fcb9b-adfb-42d3-9b80-9b55088cceae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "EPOCHS = 35\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, EPOCHS))\n",
        "    print('Training...')\n",
        "\n",
        "    # 訓練模式\n",
        "    model.train()\n",
        "\n",
        "    for data in trainloader: # trainloader is an iterator over each batch\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        # 將參數梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # 紀錄當前 batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 計算分類準確率\n",
        "    logit, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('loss: %.3f, acc: %.3f' %\n",
        "          (running_loss, acc))    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for data in valloader:\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "\n",
        "    _, acc = get_predictions(model, valloader, compute_acc=True)\n",
        "        # Move logits and labels to CPU\n",
        "        #logits = logits.detach().cpu().numpy()\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        #eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        #nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "\n",
            "======== Epoch 1 / 35 ========\n",
            "Training...\n",
            "loss: 175.478, acc: 0.677\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.60\n",
            "\n",
            "======== Epoch 2 / 35 ========\n",
            "Training...\n",
            "loss: 168.623, acc: 0.698\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "\n",
            "======== Epoch 3 / 35 ========\n",
            "Training...\n",
            "loss: 163.112, acc: 0.711\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "\n",
            "======== Epoch 4 / 35 ========\n",
            "Training...\n",
            "loss: 157.072, acc: 0.744\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "\n",
            "======== Epoch 5 / 35 ========\n",
            "Training...\n",
            "loss: 151.195, acc: 0.754\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "\n",
            "======== Epoch 6 / 35 ========\n",
            "Training...\n",
            "loss: 145.896, acc: 0.773\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "\n",
            "======== Epoch 7 / 35 ========\n",
            "Training...\n",
            "loss: 140.078, acc: 0.790\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "\n",
            "======== Epoch 8 / 35 ========\n",
            "Training...\n",
            "loss: 135.148, acc: 0.806\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "\n",
            "======== Epoch 9 / 35 ========\n",
            "Training...\n",
            "loss: 129.663, acc: 0.813\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "\n",
            "======== Epoch 10 / 35 ========\n",
            "Training...\n",
            "loss: 124.711, acc: 0.843\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "\n",
            "======== Epoch 11 / 35 ========\n",
            "Training...\n",
            "loss: 119.587, acc: 0.841\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "\n",
            "======== Epoch 12 / 35 ========\n",
            "Training...\n",
            "loss: 115.062, acc: 0.854\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "\n",
            "======== Epoch 13 / 35 ========\n",
            "Training...\n",
            "loss: 110.288, acc: 0.868\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "\n",
            "======== Epoch 14 / 35 ========\n",
            "Training...\n",
            "loss: 105.955, acc: 0.873\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "\n",
            "======== Epoch 15 / 35 ========\n",
            "Training...\n",
            "loss: 101.297, acc: 0.883\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "\n",
            "======== Epoch 16 / 35 ========\n",
            "Training...\n",
            "loss: 97.281, acc: 0.902\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "\n",
            "======== Epoch 17 / 35 ========\n",
            "Training...\n",
            "loss: 93.148, acc: 0.912\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "\n",
            "======== Epoch 18 / 35 ========\n",
            "Training...\n",
            "loss: 89.309, acc: 0.915\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "\n",
            "======== Epoch 19 / 35 ========\n",
            "Training...\n",
            "loss: 85.242, acc: 0.925\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "\n",
            "======== Epoch 20 / 35 ========\n",
            "Training...\n",
            "loss: 81.186, acc: 0.926\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "\n",
            "======== Epoch 21 / 35 ========\n",
            "Training...\n",
            "loss: 77.713, acc: 0.936\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "\n",
            "======== Epoch 22 / 35 ========\n",
            "Training...\n",
            "loss: 74.226, acc: 0.939\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "\n",
            "======== Epoch 23 / 35 ========\n",
            "Training...\n",
            "loss: 70.508, acc: 0.947\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "\n",
            "======== Epoch 24 / 35 ========\n",
            "Training...\n",
            "loss: 67.610, acc: 0.952\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "\n",
            "======== Epoch 25 / 35 ========\n",
            "Training...\n",
            "loss: 64.244, acc: 0.958\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "\n",
            "======== Epoch 26 / 35 ========\n",
            "Training...\n",
            "loss: 60.730, acc: 0.961\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "\n",
            "======== Epoch 27 / 35 ========\n",
            "Training...\n",
            "loss: 58.072, acc: 0.963\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "\n",
            "======== Epoch 28 / 35 ========\n",
            "Training...\n",
            "loss: 55.272, acc: 0.963\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 29 / 35 ========\n",
            "Training...\n",
            "loss: 52.385, acc: 0.968\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 30 / 35 ========\n",
            "Training...\n",
            "loss: 49.777, acc: 0.977\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 31 / 35 ========\n",
            "Training...\n",
            "loss: 46.916, acc: 0.976\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 32 / 35 ========\n",
            "Training...\n",
            "loss: 44.375, acc: 0.977\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 33 / 35 ========\n",
            "Training...\n",
            "loss: 42.088, acc: 0.982\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 34 / 35 ========\n",
            "Training...\n",
            "loss: 39.591, acc: 0.981\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 35 / 35 ========\n",
            "Training...\n",
            "loss: 37.625, acc: 0.985\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obfPUlEDdErS",
        "colab_type": "text"
      },
      "source": [
        "#### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKSRX3BqZs2M",
        "colab_type": "code",
        "outputId": "aaabd8c2-d70b-4dc1-d2c2-cfee9fad81a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "output_dir = os.path.join(\"model\", \"70%labeled\")\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model/70%labeled\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model/70%labeled/vocab.txt',\n",
              " 'model/70%labeled/special_tokens_map.json',\n",
              " 'model/70%labeled/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF7CqF2Wcy7r",
        "colab_type": "text"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsP0t1XddC7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大\n",
        "#testset = OnlineQueryDataset(\"test\", tokenizer=tokenizer)\n",
        "testloader = DataLoader(testset, batch_size=32, \n",
        "                        collate_fn=create_mini_batch)\n",
        "\n",
        "# 用分類模型預測測試集\n",
        "predictions = get_predictions(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9j9bSktdDIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(label, pred):\n",
        "  return (label == pred).sum().item()/len(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23PNXZRMLKkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label = torch.cuda.FloatTensor(testset.df['index'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V2IupEzdDBj",
        "colab_type": "code",
        "outputId": "584b6d59-31d1-4c04-eca1-7dd6dca98a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Testset accuracy: %f\" % accuracy(test_label, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testset accuracy: 0.822400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKoUtI9Pefds",
        "colab_type": "text"
      },
      "source": [
        "若有把太少sample的組別以及太長的問題刪掉的話（用preprocessing function），可達準確率84%左右"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi1UPDyqZ890",
        "colab_type": "text"
      },
      "source": [
        "### **2. 加入unlabel data一起train bert**\n",
        "Random sample出大約3177筆Unlabelled資料（須經過rule based過濾 ex: 長度/數字更換/drop duplicate等等），將它丟進原本bert model做分類，然後再用317 + 3177筆labeled的資料重新train一個Bert model。再用此model預測剩下那30% labeled的testing data成效如何"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYN8esV4dXGK",
        "colab_type": "text"
      },
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZnGq36cu_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVn9kwsuOULh",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess the unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkp628tbQu6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unlabel_path = os.path.join(\"data\", \"0226unlabel\")\n",
        "if not os.path.exists(unlabel_path):\n",
        "    os.makedirs(unlabel_path)\n",
        "\n",
        "# cleaned_wo_punc.csv 是將原本的4個unlabel data file合併\n",
        "# （共17000筆），並把多餘的標點符號\b空格刪除了\n",
        "df_unlabel = pd.read_csv(\"cleaned_wo_punc.csv\", sep = \"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bZKvXnDQ49Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_5PvpXQ47Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toolongshort(x):\n",
        "    return len(x) > MAXLENGTH or len(x) < MINLENGTH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ5XrVGPQ45I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def containsPhone(x):\n",
        "    pattern = r\"(0\\d{1,2}(\\d{6,8})|0\\d{1,2}-?(\\d{6,8})|09\\d{2}-?(\\d{3})-?(\\d{3}))\"\n",
        "    prog = re.compile(pattern)\n",
        "    if prog.match(x):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzByeR96OToZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def containsAddr(x):\n",
        "    pattern = r\".*(路|縣|市|街|巷|號|樓).*\"\n",
        "    prog = re.compile(pattern)\n",
        "    if prog.match(x):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXtkw8kQReSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 包含抱歉的句子幾乎都其實沒有要問事情\n",
        "def containSorry(x):\n",
        "    pattern = r\".*(對不起|抱歉|sorry|錯了|不好意思).*\"\n",
        "    prog = re.compile(pattern)\n",
        "    if prog.match(x):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskmlRQNReQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tobefiltered(x):\n",
        "    return containsPhone(x) or toolongshort(x) or containsAddr(x) or containSorry(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE33JFTHReN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 用一些rule來過濾出不適合的資料集\n",
        "# Output一個更新後的dataframe\n",
        "MINLENGTH = 5\n",
        "MAXLENGTH = 20\n",
        "def preprocessing(df):\n",
        "    # drop the duplicate question in the dataset\n",
        "    df = df.drop_duplicates(subset='question')\n",
        "\n",
        "    # drop question with phone number and filter out long question\n",
        "    df = df[~(df[\"question\"].apply(tobefiltered))]\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkVWTt4CReLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unlabel_clean = preprocessing(df_unlabel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPBQFpkhR0XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random sample出大約3177筆Unlabelled資料，利用先前的bert model來自動分類，\n",
        "# 再將這些資料加入原本的training set重新train一個bert\n",
        "df_unlabel_train = df_unlabel_clean.sample(n=3177, random_state=1)\n",
        "df_unlabel_train.to_csv(os.path.join(unlabel_path, \"unlabel_test.tsv\"), sep=\"\\t\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9rqKD9naIkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_unlabel_train目前尚無標籤，將這些視為test set放入bert分類\n",
        "testset = OnlineQueryDataset(\"test\", tokenizer, perc = 75, path = os.path.join(unlabel_path, \"unlabel_test.tsv\"))\n",
        "testloader = DataLoader(testset, batch_size=32, collate_fn=create_mini_batch)\n",
        "\n",
        "# 用分類模型預測測試集\n",
        "predictions = get_predictions(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob_Y6fzEX5tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 把欲操出來的分類放到index column\n",
        "df_unlabel_train['index'] = np.array(predictions.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LQZiaGfYYMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 與原本的trainset合併，共有3177+3177筆新的training set\n",
        "df_new_train = pd.concat([df_unlabel_train, df_train])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yz8030aWZCzT",
        "colab": {}
      },
      "source": [
        "df_new_train.to_csv(\"trainset.tsv\", sep = \"\\t\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4XKeejDiOWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = OnlineQueryDataset(\"train\", tokenizer=tokenizer, perc = 100, path = \"trainset.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNo6BX--ZLmr",
        "colab_type": "text"
      },
      "source": [
        "#### Retrain a bert model with 6354 training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5V8suMTZoUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
        "NUM_LABELS = len(df_new_train['index'].value_counts())\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRLJF0M7pwWz",
        "colab_type": "code",
        "outputId": "f397f0c1-4989-4408-f960-7fd9db9e8580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "model = model.to(device)\n",
        "\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "EPOCHS = 35\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, EPOCHS))\n",
        "    print('Training...')\n",
        "\n",
        "    # 訓練模式\n",
        "    model.train()\n",
        "\n",
        "    for data in trainloader: # trainloader is an iterator over each batch\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "\n",
        "        # 將參數梯度歸零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # 紀錄當前 batch loss\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # 計算分類準確率\n",
        "    logit, acc = get_predictions(model, trainloader, compute_acc=True)\n",
        "\n",
        "    print('loss: %.3f, acc: %.3f' %\n",
        "          (running_loss, acc))    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for data in valloader:\n",
        "        \n",
        "        tokens_tensors, segments_tensors, \\\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            outputs = model(input_ids=tokens_tensors, \n",
        "                        token_type_ids=segments_tensors, \n",
        "                        attention_mask=masks_tensors, \n",
        "                        labels=labels)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "\n",
        "    _, acc = get_predictions(model, valloader, compute_acc=True)\n",
        "        # Move logits and labels to CPU\n",
        "        #logits = logits.detach().cpu().numpy()\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        #eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        #nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "\n",
            "======== Epoch 1 / 35 ========\n",
            "Training...\n",
            "loss: 36.268, acc: 0.986\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 2 / 35 ========\n",
            "Training...\n",
            "loss: 33.903, acc: 0.987\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "\n",
            "======== Epoch 3 / 35 ========\n",
            "Training...\n",
            "loss: 31.953, acc: 0.986\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 4 / 35 ========\n",
            "Training...\n",
            "loss: 30.145, acc: 0.987\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 5 / 35 ========\n",
            "Training...\n",
            "loss: 28.237, acc: 0.989\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 6 / 35 ========\n",
            "Training...\n",
            "loss: 26.808, acc: 0.990\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 7 / 35 ========\n",
            "Training...\n",
            "loss: 25.050, acc: 0.990\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 8 / 35 ========\n",
            "Training...\n",
            "loss: 23.748, acc: 0.991\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 9 / 35 ========\n",
            "Training...\n",
            "loss: 22.331, acc: 0.992\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "\n",
            "======== Epoch 10 / 35 ========\n",
            "Training...\n",
            "loss: 20.934, acc: 0.992\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 11 / 35 ========\n",
            "Training...\n",
            "loss: 19.601, acc: 0.992\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 12 / 35 ========\n",
            "Training...\n",
            "loss: 18.455, acc: 0.992\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 13 / 35 ========\n",
            "Training...\n",
            "loss: 17.284, acc: 0.993\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 14 / 35 ========\n",
            "Training...\n",
            "loss: 16.242, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 15 / 35 ========\n",
            "Training...\n",
            "loss: 15.343, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 16 / 35 ========\n",
            "Training...\n",
            "loss: 14.504, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 17 / 35 ========\n",
            "Training...\n",
            "loss: 13.341, acc: 0.993\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 18 / 35 ========\n",
            "Training...\n",
            "loss: 12.626, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 19 / 35 ========\n",
            "Training...\n",
            "loss: 11.885, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 20 / 35 ========\n",
            "Training...\n",
            "loss: 11.090, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 21 / 35 ========\n",
            "Training...\n",
            "loss: 10.447, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 22 / 35 ========\n",
            "Training...\n",
            "loss: 9.828, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 23 / 35 ========\n",
            "Training...\n",
            "loss: 9.214, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 24 / 35 ========\n",
            "Training...\n",
            "loss: 8.625, acc: 0.994\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 25 / 35 ========\n",
            "Training...\n",
            "loss: 8.097, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 26 / 35 ========\n",
            "Training...\n",
            "loss: 7.582, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 27 / 35 ========\n",
            "Training...\n",
            "loss: 7.177, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 28 / 35 ========\n",
            "Training...\n",
            "loss: 6.752, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 29 / 35 ========\n",
            "Training...\n",
            "loss: 6.425, acc: 0.995\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 30 / 35 ========\n",
            "Training...\n",
            "loss: 5.958, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 31 / 35 ========\n",
            "Training...\n",
            "loss: 5.710, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 32 / 35 ========\n",
            "Training...\n",
            "loss: 5.382, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "\n",
            "======== Epoch 33 / 35 ========\n",
            "Training...\n",
            "loss: 4.965, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 34 / 35 ========\n",
            "Training...\n",
            "loss: 4.806, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "\n",
            "======== Epoch 35 / 35 ========\n",
            "Training...\n",
            "loss: 4.581, acc: 0.996\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwddq5HyfXlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = OnlineQueryDataset(\"test\", tokenizer=tokenizer, perc=70, path = \"data/0226label/70%test.tsv\")\n",
        "testloader = DataLoader(testset, batch_size=32, \n",
        "                        collate_fn=create_mini_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqcRq2GFZKb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 用分類模型預測測試集\n",
        "predictions_with_unlabel = get_predictions(model, testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXxfXDAgZKnc",
        "colab_type": "code",
        "outputId": "1a1f2359-ea45-4c5f-dfe1-b5c0fc0de015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Testset accuracy with unlabel data: %f\" % accuracy(test_label, predictions_with_unlabel))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testset accuracy with unlabel data: 0.820800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orEiFlb0f7qG",
        "colab_type": "text"
      },
      "source": [
        "沒有什麼進步XD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BattmeiTgI0Z",
        "colab_type": "code",
        "outputId": "f845e1e8-5b16-4cad-863c-afc2a86b48e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "output_dir = os.path.join(\"model\", \"70%withunlabeled\")\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to model/70%withunlabeled\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model/70%withunlabeled/vocab.txt',\n",
              " 'model/70%withunlabeled/special_tokens_map.json',\n",
              " 'model/70%withunlabeled/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzFWz9w9gR1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}